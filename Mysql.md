# 2024年1月22号 第64次打卡

Mysql  版本5.7

#### ==SQL语法==

1. MYSQL中字符用单引号，from可以联合多个表（但是语意模糊，建议使用子查询）

2. **AND OR**
   如果两个操作数都不为 0 (FALSE) 并且不为 NULL 时，则 AND 运算的结果为 1 
   MySQL 中没有布尔类型，AND 的运算结果是 1, 0, 或着 NULL

   - And和or两边的操作数可以是表达式也可以是值

   - **运算符优先级(优先级高的先执行) and高于or**  `SELECT 1 OR 0 AND 0;`结果为1

3. **IN (value1, value2, ...)**
   IN 运算符其实是多个 OR 运算符组合的简化版本，当左侧操作数为 NULL，返回 NULL。IN 运算符左侧操作数是字段名或者值，**右侧操作数是值列表或者子查询结果**，做操作数的值在右操作数中（等值匹配）

4. **范围查询**

   - between i and j 左闭右闭，可以为数值或者时间
   - a>i and a<j

5. **等值查询**

   - 多个字段的等值查询`where vend_country='USA' and vend_country='CA'`可以变为 `(vend_country,vend_country)=('USA','CA')`

6. **模糊匹配** 通配符 **like / not like**

   - % 匹配零或多个任意字符。 `a like '%item%'`
   - _ 匹配单个任意字符。如果需要匹配通配符，则需要使用 \ 转义字符，如 \% 和 \_。

7. 函数/表达式  用在select,where中 **字符串/日期/数字函数**

   - `select prod_id,prod_price,prod_price*0.9 as sale_price from Products` **新列为sale_price 为prod_price乘以 0.9**

   - concat(a,b)连接两个字符串，upper(a)字符串变大写，left(a,len)返回a前len个字符，substr(a,start,len)返回字符串a从start位置开始的len个子字符串，索引从1开始
     `select upper(concat(left(cust_contact,2),left(cust_city,3)))  as user_login from Customers`
     
   - if函数

     ```
     SELECT prod_name,IF(orders IS NULL,``0``,orders) AS orders  如果orders字段的记录为null，则改写为0，否则为orders不变
     ```

   - **聚合函数**：**应用于group by子集**。**sum**(a) 计算所有记录a字段的和。**count**计数 `select count（*） from table`。**max**()最大值。**min**()最小值。**avg**()平均值。

8. **EXISTS**
    用于判断字查询是否成立。如查找存在订单的客户 `SELECT customer_name FROM customers WHERE EXISTS(SELECT * FROM orders WHERE order.customer_id=customer.customer_id)`主查询为customer_name客户，字查询为订单表中是否存在该客户的记录，会检查customer的每行，满足则返回true，主查询中客户将被选择，**用于条件判断** ，`EXISTS` 不关心子查询中的列的数量或者名称，它只在乎子查询是否返回数据行。所以在 `EXISTS` 的子查询中，无论你是使用 `SELECT 1` 还是 `SELECT *`，亦或是 `SELECT column_list`，都不影响 `EXISTS` 运算的结果。**有时EXISTS可以用IN来代替**

9. **order by**
   字段可以指定一个或多个字段。**默认升序排列`order by list ASC/DESC`,==确保order by为最后一条子句==**，**同时order by 最后执行因此可以使用列别名和聚合好的列**。使用**case**可以自定义排序，`ORDER BY CASE rating    WHEN 'G' THEN 1    WHEN 'PG' THEN 2    WHEN 'PG-13' THEN 3 END;`或使用**filed** `ORDER BY FIELD(rating, 'G', 'PG', 'PG-13', 'R', 'NC-17');`,

   - order by后面可以有多个字段A，B，先根据A排序，再对A中的结果根据B排序

10. **LIMIT** 
    可以接受两个参数offset偏移量和row返回行数，offset可省略。 `limit 2 5`从第三行开始，返回5个。**limit经常和order by联合使用** `select * from table where ... order by asc limit 5`**先order by再limit。也常用于分页**

    - 获得第N大的：先order by再limit

11. **distinct** 
      去除重复记录 `select distinct column from table`,distinct后面可以为一个或多个字段，**多个字段时这些字段都完全一样的行才会去除**，distinct必须放在开头，**往往用于返回不重复记录的条数，而不用他来返回不重复记录的所有值，因为distinct只能返回目标字段，而无法返回其他字段**

     - group by去重优于distinct,得到某个字段不重复的所有记录：可以用group by，select id，name from table group by name

12. **join** 多表联合查询根据on的条件组成一张新的临时表 水平连接
     将多个表组合起来。（内连接、左连接、右连接、交叉连接）。
      **交叉连接返回两个表中所有行的所有可能组合（m*n）**。`select tableA.*,tableB.* from tableA cross join tableB` 。内连接`SELECT  student.*,  student_score.* FROM  student  INNER JOIN student_score  ON student.student_id = student_score.student_id;`按照条件的交叉连接。
    
    - 右/左外连接：左表的每一行匹配右表每一行，满足条件的右表记录留下，否则与null拼接。
      <img src="C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240421175024618.png" alt="image-20240421175024618" style="zoom:33%;" /><img src="C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240421175034152.png" alt="image-20240421175034152" style="zoom:33%;" />
    - **内连接：默认join，返回两个表中都符合条件的。只有当两个表都存在满足条件记录才返回行，其中ON和where过滤条件相等，可以在where中指定连接条件和过滤条件，也可以在on中指定连接条件和过滤条件，也可以在on中指定连接条件，在where中指定过滤条件。但是将连接条件放在on中，过滤条件放在where中语意更明确** **==外连接中on过滤条件在连接之前（即分组之前==），where操作在连接之后，因此on中只写连接条件，将过滤条件放到where中**
      <img src="C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240421175058992.png" alt="image-20240421175058992" style="zoom:33%;" />
    - 全外连接 left UNION right
    - 对记录为null的字段count为0[列出供应商及其可供产品的数量_牛客题霸_牛客网 (nowcoder.com)](https://www.nowcoder.com/practice/17f22851cf204019b51a36761a3afc79?tpId=298&tags=&title=&difficulty=0&judgeStatus=0&rp=0&sourceUrl=%2Fexam%2Foj%3Fpage%3D1%26tab%3DSQL%E7%AF%87%26topicId%3D298)
    
13. **group by** 
     `select column1，column2，aggregate_fun(ci) from table [where...] group by column1 [having]` **where和having是可选的**，**where过滤结果集，having过滤分组数据**，aggregate_fun(ci)是聚合函数（sum avg count max min等）`SELECT last_name, COUNT(*) FROM actor GROUP BY last_name ORDER BY COUNT(*) DESC;`先group by分组再order对分组排序。**where在group和聚合函数前进行过滤，having在group和聚合函数后过滤，因此where中不能有聚合函数，having中只能用select中的字段和聚合函数**

     - group by和order by，因为order by要放到最后一个子句，group by先执行，order by对groupby每个分组排序
     - 因此where中不能有聚合函数，having中可以对分组后的数据进行过滤，可以使用聚合函数和select中列名
     - mysql中使用group by时select查询语句只能是**聚合函数**和**group 条件列**，因此要显示多个列时只能添加group by条件列
    
14. 窗口函数
     [【MySQL】窗口函数详解（概念+练习+实战）_mysql 窗口函数-CSDN博客](https://blog.csdn.net/CoderSharry/article/details/135063960)

     与带有聚合函数的group by一样，窗口函数也对分组子集进行函数计算，但是不会每组返回一个值，聚合函数与groupby对一组值进行计算只返回单一的值，而有时候需要了解前几名，各个班的前几名，需要每个组返回多个值。函数作用于每个窗口

     `select 目标列，窗口函数(窗口中列 over (partition by 分组列 order by  排序列 rows between 开始行 and 结束行 ) as 窗口函数结果列别名 from table`
    sum会作用于窗口每个分组。窗口函数可以为avg，sum，count，min，max，专用窗口函数RANK、DENSE_RANK、ROW_NUMBER按顺序对每个分组中每个记录给一个序号,排序函数按照每个窗口中的order by进行排序
     <img src="C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240421001221309.png" alt="image-20240421001221309" style="zoom:50%;" />
    
15. **union** 垂直连接
     **合并两个select操作结果集**  `SELECT statement UNION [DISTINCT | ALL] SELECT statement`  **union双方的列数必须一样**，且会删除重复项，union all不会删除重复项，可以union完后进行排序，若列名不一样指以第一个结果集的列作为列名

16. date和datetime和timestamp
     date只包含年月日YYYY-MM-DD（使用三个字节），datetime包含年月日小时分钟秒毫秒YYYY-MM-DD HH:mm:ss

     - 按时间范围匹配 `where Date(order_date) between '2020-01-01' and '2020-01-31' `Date()可以提取y-m-d值，也可以用like模糊匹配 `like '2020-01'`,year()函数可以得到年 `year(order_date)='2020'`,month()匹配月，day()匹配日，date_format(order_date,'%Y-%m-%d')按照格式显示日期

17. 别名 as

     -  **对于select子语句起别名** （select。。。from。。。）as a，**join没有别名**
     - as可以省略 `select vend_name as vname from Vendors order by vname` ，where时还没有别名，order by时已经有别名了，可以使用别名

18. 子查询

     将一个查询语句作为主查询语句的**数据来源from**或**条件where**，from后时相当于返回一张临时表，**实现多表联合查询**，where后作为查询条件，字查询可以进行多层嵌套

     - **有时子查询可以代替连接**，尽量用连接而不是子查询，子查询中不能使用limit
     - 子查詢（。。。） as a需要有別名 

1. #### MySQl基础

   1. DDL 数据定义语言 create drop alter truncate
   2. DML 数据操纵语言 增删改 insert update delete
   3. DQL 数据查询语言 select
   4. DCL 数据控制语言  用来授权或回收数据库用户的某种权限，并控制数据库事务 


#### ==架构：==

- connectors：Mqsql服务器外的客户端（与语言相关，如java使用jdbc，不同语言与sql交互），与连接池连接。

- 连接层：客户端与服务端TCP连接，权限认证、身份认证等。可以有多个客户端与服务器连接，每个客户端也可以服务器建立多个连接。有两个池，TCP连接池限制连接数量。线程池，TCP连接收到请求后，分配一个线程与客户端交互

- 解析与优化：sql接口、解析器、优化器、查询缓存。sql接口接受sql命令，返回查询结果。解析器，语法、语意分析并生成解析树，语法报错信息在此处产生。优化器，确定sql语句的执行路径，生成执行计划。查询缓存之后被舍弃，因为命中率极低

- 存储引擎：插拔式的存储引擎，与文件系统进行交互，真正负责mysql中数据存储与提取

- ![image-20240122102708578](C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240122102708578.png)

  5.7之前有查询缓存（以k-v的形式缓存查询结果，k必须与sql语句一模一样才返回），5.7之后被舍弃

##### 连接器

- 有客户端的连接数量限制由max_connections 参数控制，分为长连接与短连接（也要经过三个握手，四次挥手），但是长连接占用内存增多，若累计很多连接没有断开释放内存资源，可能会导致Mysql服务占用内存过大被系统强制杀掉，回发生Mysql服务异常重启的现象。解决方式有：定期断开长连接，客户端主动重置连接（是个接口函数不是命令，不用重连只是释放内存）。
- 用户的权限逻辑判断基于在连接时读取到的权限，当权限被修改，也只有再次连接时才会使用心得权限设置

##### 查询缓存

- 当建立完连接后客户端就可以向Mysql服务发送sql语句了，当收到sql语句后，回解析出sql语句的第一个字段，若为select查询语句，则先去查询缓存（以k-v形式保存在内存中，k为sql语句，v为结果），若已执行过该命令则返回缓存中的结果，若没有则继续下步执行，并将结果存入缓存中。
- 但是查询缓存命在8.0版本后被删除了，表中数据一旦有更新操作，那么查询缓存就回被清空。对于频繁更新的表，命中率极低。8.0之前的版本，查询缓存可以通过将参数 query_cache_type 设置成 DEMAND进行关闭。

##### 解析Mysql

- 在执行sql语句前，会用解析器对sql语句进行解析，进行词法分析（识别出关键字如select from）与语法分析（根据语法规则生成sql语法树），便于后续模块获取表明，字段名，条件等等。并且会对语句语法进行检测，

##### 执行sql 

- 准备阶段：查询语句中的表与字段是否存在，将*替换为表中所有列
- 优化阶段：优化器，选择查询成本最小的执行计划，生成执行计划（如有多个索引时决定使用哪个索引）
  [MySQL 覆盖索引详解 - 掘金 (juejin.cn)](https://juejin.cn/post/6844903967365791752)
- 执行阶段：执行器和存储引擎交互，交互是以记录为单位的（**执行引擎以记录为单位返回，执行器使用while循环读取记录进行判断**），三种执行方式，主键索引查询，全表扫描（没有使用索引，效率最低），索引下推（如果有些字段没办法走联合索引就索引下推，减少二级索引查询时的回表操作）

##### explain

![image-20240423204953757](C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240423204953757.png)

- select_type:表示本行是简单还是复杂select。simple表示不包含子查询和union，primary表示包含子查询或者union。derived表示该临时表是从子查询派生出来的。
- table：表示使用的是哪张表的表名，包括临时表
- type: 访问类型。
  - index-range：索引合并，针对and和or，对查到的主键值先合并再回表
  - ALL表示全表扫描没有使用索引（效率最低）。随机IO
  - index也是全表扫描（全索引扫描），比ALL只是避免排序（效率也很低）（不回表则extra会有using index）。因为索引是排序的，会顺序IO
  - range索引范围扫描，当时用比较符号> <时。
  - ref非唯一索引等值匹配扫描，因为非唯一的所有会进行小范围的范围扫描，但是不用扫全表，因为索引有序。会查到主键再回表（不回表则extra会有using index）
  - eq-ref唯一索引等值扫描，通常在多表联合查询中on使用唯一索引或主键，如a.id=b.id。
  - const只返回一行记录的唯一键或主键的与常量的等值扫描。当最多只会有一行匹配时如等值查询,如a.id=1，主键是唯一的所以非常快。
- key:表示执行过程使用了哪个索引，PRIMARY表示使用主键索引，key为null表示没有使用索引，这里key表示使用了idx_class索引
- key_len表示索引的长度：如：使用索引字段为varchar(10),则长度为10+null值字段列表
- rows：找到结果所读取的行数，估算值。
- extra：额外信息，
  - using index_condition表示使用了索引覆盖（即二级索引就能找到查询的结果），
  - using filesort当查询语句使用group by或order by且字段不是索引时，即没使用索引的排序，需要进行额外的排序。
  - using tempory使用的临时表保存中间结果，对group by或order by、union、子查询时连接使用临时表。**在磁盘中创建临时表的成本最大**（排序、分组、去重、聚合、连接时如果**内存不足以容纳查询结果则可能将中间结果存在磁盘的临时表中**）

#### ==存储引擎==

- 不同存储引擎的表的结构不一样，即**存储引擎代表着表的类型**，接收上层传下来的指令，对表中的数据进行写入或读取
- 二者不是替代关系，而是各自具备优劣势
- InnoDB：5.5之后版本默认，支持**外键**，**支持事务**（提交与回滚），若服务器崩溃，重启服务器后不用额外操作，自动从崩溃点继续执行，有大量**更新与删除**操作，推荐使用Innodb，支持**行锁**（颗粒度更细）。但是**写效率低**，对**内存要求高**（数据与索引一起存）
- MyISAM：5.5之前版本默认，更适合处理数据量较小的表，支持表锁（并发性低），数据与索引分开存储，**访问速度快**
  ![image-20240122160517901](C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240122160517901.png)

1. InnoDB存储引擎

##### -mysql一行记录如何存储

1. 表的文件结构(三个)：db.opt用于保存默认字符集和校验规则。ibd存放表数据、索引，也称为**独占表空间文件**，也可以存放在共享表空间中（ibdata1）。frm存放表结构

2. 表空间结构：行（记录按行存放）、页（一页16kb，为数据库一次读入内存的最小单位，有数据页、溢出页、日志页等，页之间使用双向链表连接）、区（**当数据量大时，为某个索引分配空间以区为单位分配空间，每个区1mb，相当于64个页的物理位置是连续的，保证页物理上是连续的可以顺序IO，每个区相当于一个索引**）、段（表空间是由各个段组成的，**数据段存放B+树叶子节点，索引段存放B+树非叶子节点，回滚段存放的都是回滚的区，每个段相当于一类索引**）

3. 行格式：基于紧凑的Compact格式 默认使用 **Dynamic** 行格式。

   一行记录 真实数据长度+变长字段列表+null值列表的大小不能超过65535字节
   ![image-20240124104427376](C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240124104427376.png)

   变长字段长度列表：逆序存放每列记录占用字节数（ascii码一个字符占一个字节），当没有变长字段（即不为varchar（n））时就没有该长度列表了。**每个变长字段的长度小于255则使用一个字节，否则使用两个字节**

   NULL值列表：**以整数字节的形式保存逆序的二进制，列为null时二进制位为1，不为null二进制位为0**，高位补0。null值列表也不是必须的，当字段都为notnull时就不用。

   记录头信息：指向下一行记录的记录头信息。标示该行数据是否删除。当前记录的类型（普通记录，非叶子节点，最小记录，最大记录）

   row_id:占6个字节，非必须，当指定了主键或唯一约束列，则没有该字段。否则InnoDB会为记录添加一个id字段。

   trx_id:6个字节，标示这个记录时由哪个事务产生的

   roll_pointer:7个字节，这个记录上一个版本的指针。

4. 不包括隐藏列和记录头信息，所有列（包含变长字段长度列表，NULL值列表，真实数据）占用字节不能超过65535.

5. 行溢出：一页为16kb=16384字节，而一行记录最大为65535字节，因此一页可能存不下一行记录，所以多的数据就会存储在溢出页当中，compact使用20个字节存储指向溢出页的地址，而在dynamic中使用的是完全溢出的方式，即所有真实数据都存放在溢出页中，而真实记录字段值存放指向溢出页的地址。

6. char和varchar

   - varchar是变长的，最长65535，char是固定长度，最长255字节
   - 磁盘存储：char会将尾随空格去掉（因为存储时会用空格填充到指定长度，取出时会取出空格），varchar不会
   - 都会用额外信息存储字符串长度
   - 性能：**char会填充空格导致存储空间浪费，但是当遇到频繁修改的字段时，因为提前分配好了固定空间，不会导致页分裂等后续数据变动从而引起性能下降**
   - varchar(100) 和 varchar(10)当只使用了5字节时，在**磁盘**中占用的空间是一样的（根据实际长度分配），但是在
   - **内存**中的消耗不一样，内存会分配固定的大小来保存值。即对储存没有影响，对查询会有影响[浅析char与varchar类型、varchar(100)和varchar(10)的区别、varchar最大长度是多少可以存多少汉字、字符/字节/位之间的关系 - 古兰精 - 博客园 (cnblogs.com)](https://www.cnblogs.com/goloving/p/15027806.html)

##### -如果MySQL的内存特别大，是否能代替Redis

MySQL内存特别大，相当于数据大部分都保存在BufferPool中。**但是MySQL的bufferpool、日志、事务都是面向磁盘性能设计**的，如MySQL在查数据的时候，要走B+树索引，其目的是减少在磁盘的IO次数，而在Redis中比如hash对象，只需要通过o（1）时间复杂度就可以查到数据。其次MySQL更新数据时，为了事务的隔离性需要加锁，而Redis中单线程不用加锁，效率更高。此外MySQL需要将redolog和undolog进行刷盘，而Redis可选择不进行持久化。

#### ==BufferPool==

##### -为什么要有Buffer pool？

Free空闲页链表、Flush脏页链表、LRU链表（干净页和脏页）

- 因为mysql的数据是存储在磁盘中的，每次都从磁盘中读取数据性能太低。**因此数据从磁盘中获取数据之后存入缓冲池中，下次查询同样的数据从内存中获取。**
- 读：如果缓存中有客户端就直接读缓存中的数据，如果没有再从磁盘中读
- 写：直接修改缓存中的数据所在页，并标记为脏页，后台线程刷新到磁盘中
- 多大？：128MB，可以 `innodb_buffer_pool_size` 来调整
- 缓存什么？：Mysql启动后InnoDB为Bufferpool申请一片连续的空间，按照16kb的大小划分出一个个页，这些页都是空闲的，随着程序的运行，才会有磁盘上的页缓存到Bufferpool中，包括数据页、索引页、还有undo页、插入缓存页、锁信息等。每个缓存页都有一个**控制块**，其中包括了缓存页的**表空间、页号、缓存页地址、链表节点等。**（所在表、表中的页号、具体缓存地址）
- 如何管理空闲页？将空闲的缓存页的控制块作为链表的节点组成一个Free链表。当磁盘每加载一页到BufferPool中时，从**Free链表**取一个空闲的缓存页，并把该缓存页的控制块从链表中移除。
- 如何管理脏页：更新数据时，不需要每次都写入磁盘中，而是标记为脏页，后台线程写入磁盘。**Flush链表**，节点也是控制块，其中每个元素都是脏页。后台线程遍历Flush链表，将脏页写入磁盘。
- 如何提高缓存命中率？：我们希望频繁访问的数据可以一直保存在缓存中，访问少的数据可以淘汰掉。保证BUfferpool不会因为满了导致无法继续缓存，同时保证高频数据在BufferPool中。使用**LRU 链表**，其中为已被使用但没被修改的数据。其中脏页同时存在与LRU链表和Flush链表中。
- 预读取失败？预读取即由于被访问的数据附近的数据，在未来也有很大概率被访问，所以Mysql在加载数据页时，会提前把相邻的数据页也加载进来，以减少磁盘IO，**但当被预读取进来的数据页并没有被访问时，为预读取失效**，当这些一直不被访问的数据占用了LRU链表前排位置，而末尾被淘汰的，可能是频繁访问的页，大大降低了缓存命中率。**因此将LRU链表划分为young区和old区**。**预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部**。
- Buffer pool污染？：当某一个 SQL 语句**扫描了大量的数据**时，在 Buffer Pool 空间比较有限的情况下，可能会将 **Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了**。等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 **Buffer Pool 污染**。因此在转入young区之前增加一个判断，第一次访问与后续访问在一个时间段内，则不会被移动到young区。**只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部**。
- 脏数据页什么时候写入磁盘？：InnoDB 的更新操作采用的是 Write Ahead Log 策略，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。
  - 1、redolog日志满了会主动触发刷盘
  - 2、BufferPool空间不足时（即被淘汰的为脏页时先将脏页刷盘再淘汰）
  - 3、Mysql被认为空闲时
  - 4、Mysql正常关闭前。
- 唯一索引和普通索引区别ChangeBuffer：
  **changebuffer只对普通索引有用，对唯一索引没有，减少对磁盘的IO**
  - 查询过程：都是B+树先从根节点开始，二分法按层搜索到叶子节，点，**唯一索引查到一个就会停，普通索引会继续查下一个记录，直到遇到第一个不满足的记录为止。**但是Innodb与磁盘交互以页为单位放到内存中，**查找唯一数据或继续查下一个数据都是在内存中的操作**，只多几次指针寻找和计算，对性能忽略不计，**查询性能一样**。
  - 写过程：**唯一索引的更新操作因为要判断唯一性，所以还是要把数据页读到内存中判断，但是都已经读到内存中了，所以读到后直接在内存中进行更新，无法使用ChangeBuffer**。而普通索引，如果数据页在内存中就直接更新，如果不在内存中，Innodb会将更新操作缓存在changeBuffer中，就不用从磁盘中读数据页了，下次查改数据时，会先把数据也读到内存中，再执行changebuffer中的缓存操作（称为merge），保证数据的一致性与持久化。merge操作会在查询数据页、系统后台线程定期、数据库正常关闭时触发，**普通索引在写多读少场景下结合changebuffer使用性能更好**。
  - ChangeBuffer使用场景：**在更新操作时，如果数据页不在内存中，先把更新操作记录在changebuffer中，当下次读取该页到内存中时，执行changeBuffer中关于该页的操作**，减少读磁盘，提升语句的执行速度，changebuffer占中bufferpool的位置，适用于**普通索引写多读少**的操作。每次读都会出发merge操作。不适用于写完了立即读的操作，不会减少磁盘io操作，还会增加维护changebuffer代价。

#### ==索引==  

 **是提升查询速度的数据结构，索引对数据进行排序，基于磁盘的数据排序，从亿级数据查询只需要3、4次IO。B+树的高度从1开始，随着索引中记录的个数变多，一个页16kb无法存储，开始分裂，非叶子节点存放的是（索引键、指针）对，叶子节点存放的是（索引键、数据）对**  

##### -InnoDB如何存储数据？

- **在一个数据页中定位到行**：按数据页为单位进行读写，大小为16kb，即数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。
  **页目录**：数据页的文件头指向上一个与下一个数据页。**数据页中的记录按照主键顺序组成单向链表存放，便于增删操作，但是检索效率不高**。因此数据页中有页目录，页分为多个组，页目录有多个槽每个槽指向所在组的最后一个记录，相当于分组记录的索引，起到记录索引的作用，每个组中的记录不会超过8个，便于用**二分法进行查找对应的分组，再遍历分组中的所有记录，找到对应的记录。无需从头到尾遍历整个页中记录**，==**先使用B+树找到所在的页号，再每个页中再按照页目录找**==，索引页记录的是（对应页中最小索引，页号对应地址），**==InnoDB会将表的索引（非叶子节点）加载到内存中==**，但是当内存装不下时就会导致磁盘IO
- **在多个数据页中定位某个数据页**：通过B+树，B+树的每个节点是一个页，**非叶子结点的页不存放数据，只存放页目录作为索引**，叶子节点存放数据。所有节点按照索引键大小排序，构成双向链表（物理上不连续看，逻辑上连续），便于范围查找。**从根节点开始不断通过对页目录二分法定位到页范围包含查询值的页**。在叶子节点二分法定位到槽所在的分组，遍历找到对应的记录

##### -什么时候需要/不需要创建索引

- 创建索引：经常作为查询条件的字段、区分度高的字段（如商品编码是唯一的）、经常用于order by、group by的字段（就不需要额外排序了）
  建立索引原则：经常作为查询条件的创建索引，多用联合索引代替单值索引，经常范围、排序、分组的创建索引，主外键或连表字段，索引字段过长考虑前缀索引，索引字段无序时不推荐建立索引，字段存在大量重复值时，不适合创建索引，**经常增删改的不适合创建索引(因为要维护索引)**
- 不创建：表中数据太少、经常更新的字段不用创建索引（需要频繁维护B+树的有序性）、区分度低的字段

##### -聚簇索引和二级索引

- 区别在于叶子节点是否存放数据，二级索引的叶子节点存放主键，聚簇索引的叶子节点存放数据。数据一定存放在聚簇索引的叶子节点上，所以**一张表的聚簇索引只有一个**。
  聚簇索引：当有主键时，主键为聚簇索引。没有主键，将不含null值的唯一约束键作为聚簇索引。都没有时，InnoDB自动生成一个隐式的自增id作为聚簇索引的索引键。
- 回表与索引覆盖：当查询语句使用二级索引，且查询的数据为主键时，在二级索引就能查到，不需要再去聚簇索引查询，称为索引覆盖。当查询语句使用二级索引且查询的数据不为主键时，需要通过二级索引查到主键再到聚簇索引钟获得记录，称为回表，要两个B+树才能查到数据。

- MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表

- B+树分为主键索引和二级索引，B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。

- 什么是索引？：索引是**用于提高数据库的查询速度的一种数据结构**。原理为**索引在插入时对数据进行排序**。Innodb实现的索引有**B+树**，全文索引等。


##### -为什么用 B+tree 作为索引的数据结构？

- 为什么用B+树？：在**磁盘的数据排序中效率最高的是B+树**，除此之外红黑树、哈希索引、二叉树等一般用于内存对象。
  Mysql索引的数据结构要满足：**尽量少的IO次数，能高效执行范围查找（即最好是排序的）**，==**访问每个页（B+树节点）都是一次IO**==。

- B+树特点：存放千万至上亿条数据的B+树通常只有三到四层，即从只要三四次磁盘IO就可以查询到一条数据。非叶子节点存放索引，叶子节点才存放数据，所有的索引都会在叶子节点中出现。每个节点都是页。通过二分法进行定位。复杂度为o(logd N) d为个节点能存放的数据个数

- **B+树的插入性能？**（有序代价小和无序插入可能也分裂、旋转等代价大）：**B+树在插入时要对数据进行排序，但是排序实际上在cpu执行**（因为将数据页读到内存中进行二分法排序），**真正开销在于对B+树的维护，保证插入后数据的排序**。当**数据是按顺序插入时**，B+树叶子节点从左向右插入维护代价很小，如插入的是自增id，时间上的插入。但**当数据是无序插入时**，需要对页进行分裂，旋转等开销较大的操作，维护B+树索引的代价较大，比如索引为昵称等，因为昵称是无序的。**B+树索引本身就是对数据进行排序用的，若要求插入数据都是有序的那么也不需要B+树了**，**==因此仅要求主键的索引设计为有序（主键索引的插入是有序的，而二级索引的插入为无序的==）**，如自增。此时主键索引是顺序插入，**但是二级索引的维护依然是无序插入**

- 索引创建：当业务需要多个维度进行查询时，就需要创建多个索引。只会发生创建了多个索引却没有被用到的情况，占用空间还影响插入性能，即是业务上的问题。**那你怎么知道哪些 B+树索引未被使用过呢**？在 MySQL 数据库中，可以通过查询表sys.schema_unused_indexes，**查看有哪些索引一直未被使用过**，可以被废弃。

- Mysql为什么使用B+树？Mysql设计索引时要满足：**==尽可能少的磁盘IO次数、支持范围查询==**。即首先要求索引时有序的（可以使用二分法查找，每次将查询范围减半，时间复杂度为logN）

  - **二叉查找树（左子树小于节点、右子树大于节点）可能会退化成链表**、

  - **自平衡二叉树（左右子树的高度差不能大于一）但是数据多的时候由于时二叉的高度会很高导致IO次数变多**、

  - **B树（每个节点可以有多个子节点，且每个节点都保存了索引与数据，会浪费内存，且范围查询要进行中序遍历、在插入删除根节点时树可能会发生变化）**、

  - **B+树（每个节点可以有多个数据**，**且只有叶子节点保存数据**，非叶子节点有多少子节点就有多少索引）、hash表，插入删除时因为每个非叶子节点都是冗余的因此删除根节点不会导致树发生复杂的变化

  - hash表等值查询的时候复杂度为o(1)非常快，但是数据并不是有序的，不能进行范围查询。

- B树与B+树对比：

  - 1、查询：因为B+树的非叶子节点不存放数据，只存放索引，因此可以放更多的索引，使得B+树更矮胖，以减少IO次数
  - 2、增加与删除，因为B+树有冗余设计，删除节点时，可以只变动叶子节点，而非叶子节点不变动，**而B树可能会导致树的结构发生变化**。

- **索引组织表与堆表**：堆表：堆表中的数据无序存放，数据与索引分来存放，索引的**叶子节点存放了数据在堆表中的地址**，索引和数据分开存储，即查到地址后还需要再次去找表，相当于两次IO，一个堆表可以对应多个索引，当堆表中数据发生改变，位置变更，所有索引中地址都要更新。而索引组织表，数据和索引在一起，**叶子节点存的是索引与数据**。

- 二者区别： 堆表插入性能高（因为堆表是无序的，不用考虑数据排序）、索引组织表的范围查询性能高（堆表要进行大量的回表操作）、且堆表只支持表锁并发性能差

  - 1、堆表是无序的，且索引都是平级的，所有索引都是二级索引，通过索引找到key再定位数据，而索引组织表要key定位到id，id再定位到数据，堆查单个数据速度快。**堆表插入数据时总是追加到堆的最后一页，而不用对页中的数据进行重组或移动，插入性能高。**
  - 2、索引组织表的叶子节点都是通过链表连接的，在范围查询时能大大节省空间，但在二级索引的范围查询时，IO次数会非常多（大量的回表）。
  - 3、堆表行数据发生变化，则每个索引都要更新，而索引组织表只会更新变化更新了的索引。

- 索引组织表和堆表的应用场景：堆表是Myism的储存方式，索引组织表是Innodb的存储方式，**堆表适用于大量插入操作，索引组织表适用于范围查询、高并发**。

- 回表：通过二级索引定位到主键，再通过主键索引进行数据查找的操作称为回表，**当数据发生变动时，二级索引不需要变动，除非主键发生变化**。

- **二级索引一般比主键索引慢**？：因为主键索引一般要求为顺序的，而二级索引可以时无序的，因此主键索引是顺序插入，二级索引插入时大部分为随机插入可能会造成索引页分裂、旋转

- **函数索引**：索引键是一个函数表达式，数据库规范要求**查询中函数要写在等式右边，而不能写在左边（因为并没有对函数处理后的索引排序，无法使用索引）**。因为`SELECT * FROM User  WHERE DATE_FORMAT(register_date,'%Y-%m') = '2021-01'只对register_date`索引进行排序了，而并没有对函数处理过的DATE_FORMAT(register_date) 进行排序，无法用到二级索引register_date。因此可以使用函数索引，**创建一个DATE_FORMAT(register_date) 的索引，就可以将函数写在等号左边**，再次使用之前的语句查询，就可以用到最新创建的函数索引，优化业务SQL性能，即**对同一份数据做了两份索引，会影响性能，要维护两个索引**，并且和虚拟列结合起来可以不用写冗长的函数

- **联合索引**：是**由多个列组成的B+树索引（变为对多个列进行排序）**,既可以是主键索引，可以是二级索引。通常用于如将某个id的订单按照时间顺序进行展示等。`select * from table where a=? order by b desc`。**联合索引遵循最左匹配原则**，在遇到>,<这种范围查询是联合索引会失效，但是在>=,<=,between and中可以用到联合索引，且建立联合索引时，要把区分度大的字段排在前面，就能过滤掉更多

  如何提升查询性能：

  - 1、组合索引**可以覆盖多个查询条件**，如（a，b）可以覆盖a=？或a=? and b=？ 
  - 2、**避免sql进行额外的排序**，如where a=？order by b ，已经对a,b进行索引排序了 （如电商业务中的按时间排序订单）
  - 3、可以**进行索引覆盖，避免回表**，提升查询性能

##### - 索引失效

**查询语句的条件用了索引列，并不意味着查询过程一定使用索引**，某些情况会发生**索引失效而进行全表扫描**。

- 1、对索引使用**左模糊或左右模糊** `like %xx 或 like %xx%`，而右模糊不会造成索引失效，**因为B+树是按照索引值的前缀进行排序的**。（但是如果查询的内容都在二级索引中，既是是左模糊，不会全表扫描，而是index与using index索引覆盖）
- 2、**查询条件对索引使用函数** `where length(name)=1`，因为索引保存的是原始值排序，不是经过函数计算后值的排序，所以会导致索引失效，在Mysql8.0后可以使用函数索引，简历经过函数计算的索引
- 3、查询条件**对索引进行表达式计算** `where age-1=5` 原因与2一样
- 4、查询条件对索引进行了**隐式的类型转换**，**==字符串和整数比较时会把字符串转数字==**，mysql在`where phone=13`会把字符串类phone转换为数字进行比较，相当于对索引使用函数，导致索引失效，而`where age="11"`会把字符串“11”转换为数字11,并不会对索引使用函数，因此不会导致索引失效。
- 5、在联合索引中**没有遵循最左匹配原则**，因为联合索引是按照第一个索引（即最左边的）排序，在第一列相同索引下对第二列索引排序。 `（a,b,c）联合索引`对条件 `where b=？and a=? 或者 where a=? `进行联合索引，但对 `where b=? 或 where b=? and c=?`会索引失效，特别的 `where a=？and c=? `索引截断会进行**索引下推**(**在存储引擎中就过滤掉不满足的记录，而不是在server层中判断，减少回表次数**)，不会在找到a=？的主键后就回表，server层从执行引擎获得数据后再对c=？进行判断，而是将在找到a=？后不回表，继续在执行引擎中继续过滤c=？找到主键，从而减少回表次数。
- 6、**在查询条件中的or中有不是索引的列**。 `where id=10 or age=5`的age不是索引，则会索引失效，进行全表扫描。因此把age也设置为索引，则innodb会对id索引和age索引分别进行扫描，然后再合并数据，从而避免全表扫描。

##### - **优化器索引选择**

：B+树索引只是存储的一种数据结构，优化器决定索引的选择。**CBO优化器（cost-based-optimizer）基于成本选择索引**，cost=server cost(cpu cost)+engine cost(io cost)，**cpu cost为计算开销，包括排序、索引对比、值对比等，IO cost包括与内存的io开销以及与磁盘IO的开销**（基于数据在内存还是在磁盘中）。 mysql 下的表 server_cost、engine_cost 则记录了对于各种成本的计算。其中**在磁盘中创建临时表的成本最大**（排序、分组、去重、聚合、连接时如果**内存不足以容纳查询结果则可能将中间结果存在磁盘的临时表中**），从磁盘中io的成本是从内存中io成本的4倍。**通过 EXPLAIN 命令查看每个 SQL 的成本；**

- **当对二级索引进行范围查询时**，可能会因为产生的大量回表操作导致使用索引的成本比全表查询的成本还大。
- **当索引创建在有限状态上**（即列只有几种选择如 已完成、支付中、超时关闭，业务上有查询的需求则创建索引，而男女这种不需要创建索引），实际上这几种状态是有倾斜的，因此使用索引查询速度会更快，而Innodb会认为这这列的状态是平均分布的，因此使用全表扫描，所以可以创建直方图，让优化器知道状态分布，从而更好的选择计划。一般只对高选择度的字段和字段组合创建索引，低选择度的字段如性别，不创建索引。**而低选择度数据如果是倾斜的，可以创建索引与直方图让优化器知道数据分布，更准确的选择执行计划**

- 使用索引的优缺点？：
  - 提升数据库整体的查询速度
  - 在分组或排序时，减少sql查询分组或排序的时机
  - 连表查询时，基于主外键字段的索引加快连表查询速度
  - B+树提升范围查询的速度
  - 但是增加磁盘负担，要额外空间存放索引。写入数据时要维护索引，有额外的时间开销，降低性能。
- 主键索引：如果主键不是有序的，那么每次插入都要对索引进行维护，因此**主键最好是顺序性的**（如自增id）
- 联合索引：只有满足最左匹配原则才能命中到联合索引，当发生索引截断（a=？，c=？）时，从Mysql5.6前会用索引a=？查到主键后开始回表，获取到行，对比c=？。在5.6之后会进行索引下推。被截断的字段不会在server层进行判断，而是下推到执行引擎层进行判断,因为c也在联合索引中，过滤出符合条件的数据返回给server层，减少回表次数。**遇到范围范围查询会停止匹配，即范围查询的字段可以用单联合索引，范围查询字段后**。
- 前缀索引：前缀索引可以节省存储空间。但是因为储存的不是完整字段，所以无法通过前缀索引进行分组group与order 排序。
- 全文索引：在模糊查询中全文索引用来代替模糊匹配like%。但是全文索引对字段分词处理，分词会存在全文索引中，会占用大量空间。对中文支持很差。
- 唯一索引：唯一索引在插入时要进行判断，效率低，在查询时速度快，相比普通索引不用继续向下查找相同字段。但是唯一索引插入时不如普通索引，当数据不在内存中时普通索引使用changebuffer，唯一索引要IO磁盘
- 哈希索引：哈希索引查询速度非常快，只需要经过一次哈希计算就可以得到数据，但是哈希索引时无序的，无法基于哈希索引做排序与分组。因此当确定不用做排序业务时，可以使用哈希结构。
- MRR机制（Multi-Range Read）：5.6推出的优化，当做范围查询时，减少离散回表（即多次回表的数据可能再重复页当中），将二级索引查出来的主键放入缓冲区，进行排序，再根据顺序IO从主键索引中查询数据。

##### - count(*)和count(1)

count(1)即记录表中1这个表达式不为NULL的记录有多少个，**count(name)即记录表中name字段不为null的记录的个数**，

- count（主键）的过程，server层会维护一个count变量，server循环从Innodb中读取一条记录，并判断指定参数是否为null，对count加1，直到记录被读完。将count记录返给给客户端。如果参数为主键，且表中只有主键索引，没有二级索引，那么会遍历聚簇索引，如果有二级索引，那么遍历的就是二级索引
- count(1)过程，**相比于count(主键),少了读取主键字段的步骤，server只要得到了记录，count就加1，比count(主键)效率稍微高**
- count(*)过程，相当于count(1),即二者执行过程基本一致
- count(字段)过程，**不是索引的字段，采用全表扫描的方式，效率最差**
- 为什么MyISAM保存了每张表的count值（并且使用表锁），而InnDB就需要进行遍历的方式呢？因为Innodb支持事务，同一时刻多个事务的查询，由于MVCC和readView，每个事务查询的结果也不一样，没办法对每个表维护一个count变量
- 如何优化大表的count(*):对于1200w的表使用二级索引进行了count( * )花费的时间超过5s。**使用explain进行估算，或使用额外的表保存计数值**

#### ==事务(ACID  5种状态)==

Innodb与MyISAM的区别之一就是Innodb支持事务。
**事务是一组操作，使数据从一种状态到另一种状态，要么都执行，要么都不执行。** 
mysql客户端与JDBC控制事务的方式同，以下为客户端控制方式。

- A:原子性Atomicity 要么全部执行，要么全部不执行，没有中间状态，**redo log重做日志保证**

- C:一致性Consistency 是事务的目的，**指事务执行前后，数据从一个合法状态变到另一个合法状态**，合法是指语意上的**合法代表着满足约束**，不是语法上的合法。如转账A账户-40，而B账户没有+40。或A付款完余额变成了负数。或唯一性的字段在操作完之后变得不唯一了。都违反了一致性的约束。**通过A I D来保障**

- I:隔离性Isolation **一个事务执行不能被其他事务干扰，即一个事务中的操作与使用的数据对其他的并发事务是隔离的**，通过**锁或MVCC**来保障，**防止多个事务并发执行的时候由于交叉执行导致数据不一致**

- D:持久性durability 即**一个事务一旦提交，对数据的修改是永久性的**，通过**日志**来保障

- 事务的状态：

  1. **活动的**（执行过程中）、
  2. **部分提交的**（最后一个操作执行完还没提交，即对内存中数据修改了，还没写磁盘）、
  3. **提交的**（将部分提交的写入磁盘）、
  4. **失败的**（即活动的与部分提交的状态中发生了错误或认为停止导致无法继续执行）、
  5. **中止的**（失败的状态需要把事务中操作还原到执行前状态，即**回滚完成**），**事务执行最终状态要么commit是提交的要么是rollback中止的**（即要么都做，要么都不做）

- 开启事务 `begin或start transaction`其中start transaction后可以添加修饰符read only只读 、read write读写、with consistent snapshot一致性读。（with consistent snapshot代表立即启动事务，否则就是执行第一条select语句才真正启动事务）

- 手动中止事务：ROLLBACK是手动回滚，如果事务在执行过程中发生了某些错误而无法继续执行，事务会进行自动回滚。在事务中可以设置**保存点**`savepoint s1` 回滚时可以 `rollback to s1` 回滚到记录保存点时所在的位置,而不是全部回滚。

- 自动提交autocommit,默认为开启的，即不显示的使用begin或start transaction开启一个事务，那么每一条语句都算一个单独的事务，想要关闭自动提交可以

  1. 手动将autocommit设置为off `set autocommit=off`
  2. 显示使用begin或start transaction开启事务，使用commit提交事务。**事务就不会自动提交**

- 隐式提交：使用begin或start transaction手动开启事务或将自动提交关闭，事务就不会自动提交，但是**某些特殊语句会导致事务隐式提交**。

  1. 使用DDL语句 create drop alter truncate
  2. 关于数据库复制的语句 如start slave 即主从
  3. 当上个事务没提交，开启新事务，上个事务会隐式提交
  4. 加载数据语句 如load data，会隐式提交之前语句的事务


##### -隔离级别如何实现？ 

 **MVCC多版本并发控制和锁 **

- **并行事务引发的问题？ **  **脏读（事务中读到的时其他事务还未提交的数据）、不可重复赌（同一个事务中多次操作读取到的数据不一致）、幻读（同一个事务中多次操作查询到的记录个数不同）**
  **一个Mysql服务器可以连接多个客户端，每个客户端与服务器连接称为一个会话session**，每个客户端都可以在自己的会话中向服务器发出请求，一个请求可能是会话的一部分，即**服务器可能同时处理多个事务**。即需要在**事务的隔离性与并发性之间进行权衡**。

  1. 脏读：一个事务A读到了另一个未提交事务B修改过的数据，若事务B进行了回滚，则事务A读到的内容就是临时且无效的
  2. 脏写：**数据没写入**，一个事务A修改了另一个未提交事务B修改过的数据，若事务B进行了回滚，则事务A的修改操作就时无效的
  3. 不可重复读：**数据不一致**，更新导致，事务A读一个字段，由于之后另一个事务B**更新**并提交了改数据，导致事务A再次读到该字段的值不一样。
  4. 幻读：**数量不一致**，插入导致（删除不算幻读，幻读强调读到了之前读取没有获得的记录），一个事务A多次读同一个数据，由于事务B**插入数据**，导致**事务A再次读数据时的记录数量不一样**

- sql四种隔离级别（**即对隔离性与并发性进行的取舍程度**）

  严重程度：脏写>脏读>不可重复读>幻读
  **隔离级别越低，并发问题就越多，隔离级别越高，并发性能越低，无论哪个隔离级别都解决了脏写的问题（读未提交没有解决脏读、脏写）**
  ![image-20240130161930431](C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240130161930431.png)

  1.  读未提交:一个事务还未提交，其修改就能被其他事务看到，即还可能发生脏读，基本不用
  2.  读已提交:解决了脏读，一个事务只能读已经被提交的数据。是Oracle默认隔离级别
  3. 可重复度:解决了脏读，可重复读。事务A读一条数据，事务B修改提交了该数据，事务A再次读还是原来的内容。是Mysql默认的隔离级别
  4. 可串行话：解决了幻读，相当于串行处理，一个事务执行期间，其他事务禁止对该数据进行增删改，对记录加**读写锁**，解决所有并发问题，但是性能低下

  - 读已提交和可重复读通过Read View来实现，**Read View相当于是对数据的快照**。**读提交是在每个语句执行前都会重新生成一个Read View，可重复读是在开启事务的时候生成一个Read View，整个事务期间都使用这个Read View**

- **Mysql默认的可重复读隔离级别，可以很大程度上避免幻读**（快照读使用MVCC，当前读使用记录锁加间隙锁解决）

- **四种隔离级别如何实现？** **读未提交：每次都读最新值。串行化：使用读写锁。读已提交和可重复读使用readView快照来实现**（读已提交只有记录锁，可重复读有记录锁、间隙锁）

- Read View如何在MVCC中工作？：

  - Read View中记录四个字段，分别是（注意是**事务的id**）
    1. 建立Read View的事务id号creator_trx_id、
    2. 创建Read View时活动且未提交的事务id列表m_ids、
    3. 创建Read View时活动且未提交的事务中id最小的事务min_trx_id即m_ids中最小值（**即存在大于min_trx_id的已提交事务，且不会在m_ids列表中**）
    4. 创建Read View时应当给下一个事务的id值max_trx_id即全局事务中最大id值+1（**不是m_ids的最大值+1，因为创建Read View时可能存在比m_ids所有值都大的事务id，且已经被提交**）
  - 聚簇索引记录中的两个隐藏列
    1. trx_id:当某个事务对当前记录改动时，就会把该事务的id记录下来
    2. roll_pointer：当对该记录进行改动时，会把旧版本的记录写到undo日志中，为一个指针，指向旧版本的记录。
  - 因此当事务去访问记录时，如果记录的trx_id小于min_trx_id,则表示该记录在创建Read View时就已经被提交，是可见的
    如果记录的trx_id大于等于max_trx_id，则表示该版本记录是在创建Read View之后才启动的事务生成的，是不可见的
    如果记录的trx_id在min_trx_id与max_trx_id之间，如果trx_id在m_ids中，则说明该版本记录在生成ReadView时还未提交，不可见（需要访问undolog版本链中小于readview的create_trx_id的第一条记录）。如果trx_id不在m_ids中，则说明改版本记录已经提交，可见。**以防止脏读**，只能读已经被提交的。

- 可重复读如何工作？
  在启动事务时生成Read View，整个事务期间都用这个Read View

- 读提交如何工作？

  在事务的每个语句读取数据时，都会生成一个新的Read View（每次的Read View中的m_ids、min_trx_id、max_trx_id可能会发生改变）

- **InnoDB默认隔离级别为可重复读（在事务开启时创建ReadView）。默认autoCommit开启，即每条语句都是一个事务**


##### -幻读被完全解决了吗？

在**可重复读隔离级别下，有两种方法能有效避免幻读**，但是并没有完全解决。**读已提交没有间隙锁**（因为间隙锁用来解决可重复读级别下的幻读，**读已提交连不可重复读都没解决**）

- 方式一：使用**MVCC进行快照读**，开始事务后，生成**ReadView相当于当前数据的快照**，通过ReadView可以通过数据的版本链在undo_log中找到事务开始时的版本的数据，所以每次查询的数据都是一样的，即使有其他事务插入了记录，当前事务也不会读到。

  但是当事务A先select后没有数据id=5，接着事务B插入数据id=5（数据版本事务B），事务A直接update数据id=5（数据版本变成事务A了），并再次select数据id=5，因为数据版本为A，事务A查到了id=5的数据，**导致了幻读（发生在先查询再更新时）**

- 方式二：使用**for update进行当前读**，**除了select普通查询以外，其他都是当前读（insert、update、delete增删改**），事务A执行该语句时会进行记录锁与间隙锁，而不是通过快照，**每次都是根据最新的数据进行操作**，此时其他事务要进行写操作都会进行等待状态，直到事务A释放锁，从而避免了由于其他事务进行插入操作导致的幻读

  但是当事务A先进行普通的select操作，事务B进行了插入操作，之后事务A在进行select for update操作会发生幻读，因此最好在事务刚开启就进行select for update操作。

#### ==锁==

锁借助索引来实现，锁住了叶子节点，与此同时与隔离级别密切相关

##### - 全局锁：

 `flush tables with read lock` 加锁 。 `unlock tables`或者会话断开，释放锁。

- 用于**数据库备份**时，防止数据备份期间，数据或表结构发生变化，导致备份数据与预期不一致。但是加锁期间数据库只读，造成业务停滞
- 在全局锁后整个数据库处于只读状态，增删改会报错。
- 替换：使用隔离级别为可重复读的事务，**在备份前开启事务**，备份ReadVIew版本的数据，由于MVCC多版本链，备份期间依然可以对数据进行更改。 `mysqldump  –single-transaction`

##### - 表级锁：

- 表锁： `lock tables  table_name read` 读锁。 `lock tables  table_name write`写锁。 `unlock tables`或结束会话进行解锁。
  读锁：**读锁即所有线程都只能对加锁的表进行读操作，开启锁的线程无法读写其他表，只能读加了读锁的表**，
  写锁：**写锁只有加锁的线程可以读写，且加锁的线程只能读写该表，不能读写其他表，其他线程无法对加锁的表进行读写**

- 元数据锁：防止当一个线程对表执行CRUD操作时，其他线程对该表进行DDL操作。
  mdl（metadata lock）对数据库操作时，**会自动为表加锁**（不用显示加锁操作）。
  **CRUD和DML 二者互斥**，如有线程执行select操作时（加mdl读锁），其他线程要修改表结构（申请mdl写锁）会被阻塞，直到select执行完（事务提交）。**即使得对表的DML操作与DDL操作不能同时发生。**

  元数据锁释放时机：在事务提交时mdl锁被释放（默认每个sql语句为一个事务）
  **造成阻塞问题**：**DDL的mdl写锁优先级高于mdl读锁**，因此当DDL被CRUD阻塞后，在该DDL之后的CRUD语句也会被阻塞。可以设置较小的阻塞等待时间，及时释放连接，避免连接被消耗完。优化事务及时提交，避免长事务的发生。

- 意向锁：**在对记录加锁（共享、独占）之前，需要在表级别加上意向锁（意向共享锁、意向独占锁**），即在增删改时**要先对表加上意向独占锁，再对记录单独加独占锁。**而普通的select不会加行级锁，而是通过MVCC实现一致性读（快照读），无锁，意向锁和表锁会发生冲突，
  - **用于快速的判断表里是否有记录被锁**，如果没有意向锁要加表锁的时候就要遍历所有记录是否存在锁。有意向锁时，那么在加表锁时直接查是否存在意向锁，就不用遍历记录了
  - 场景：意向锁代表着存在行锁，**行锁和表锁不能同时存在，即意向锁和表锁不能同时存在**
  
- AUTO—INC锁：设置了自增主键auto_increment，那么在插入时可以不指定主键值，数据库会自动给主键赋值递增的值，通过AUTO_INC锁实现。**在插入数据时，会加一个表级别的AUTO_INC锁，为设置的自增字段赋递增值，执行完插入语句后把锁释放。**
  - **有两种释放锁的时刻**： `innodb_autoinc_lock_mode `系统变量，为0时采用AUTO_INC锁，为2时采用轻量级锁，为1时普通插入用轻量锁，批量插入如insert...select采用AUTO_INC锁，1、**在插入语句执行完后释放锁**，但是在大量插入时，另一个事务会被阻塞，影响插入性能 2、在**申请完自增主键后就释放**，而不是等待整个语句执行完再释放锁
  - 为2时插入效率最高，即申请完自增主键就释放，**但是有可能会造成主从复制数据不一致**，批量插入时因为不是整个语句执行完才释放，因此在并发批量插入时可能数据不是连续的（**如线程A批量插入，B插入，导致A批量插入的顺序不是连续的**），但是当主从复制时，binlog如果为statement格式（发送的是原始sql语句而不是记录行），从库按照binlog的SQL语句顺序执行SQL语句，批量插入语句的数据就是顺序的了，因此导致主从顺序不一致，因此可以将binlog格式设置为row，按照记录执行，此时**innodb_autoinc_lock_mode = 2** 且**binlog格式为row**，并发高且不会发生主从不一致问题

##### - 行级锁：

普通的select语句不会对记录加行锁，因为使用了快照读。
**以下两种读select和删delete改update会自动加锁（update和delete加X型锁）**，**事务提交了锁就被释放**，普通select不加锁。
读已提交：只有记录锁。 可重复读：有记录所、间隙锁、临键锁

```sql
//默认对读取的记录加S型临键锁 读读
select ... lock in share mode;
//对读取的记录加X型临键锁 
select ... for update;
```

- **InnoDB支持行级锁，而MyISAM不支持行级锁**（行级锁随着事务结束被释放，而MyISAM中不支持事务）
- 记录锁Record Lock：锁住一条记录。分为共享锁和独占锁，**共享锁允许多个事务并发执行时重复添加**（即一个事务对某个记录加了共享锁，其他事务可以继续对该记录加共享锁），但是不能加独占锁。独占锁其他事务不能加任何记录锁。**事务被提交释放行锁**
- 间隙锁Gap Lock：只在可重复读级别中使用，用于当前读（select...for update）中的幻读。**间隙锁之间时兼容的，两个事务可以同时持有共同间隙范围的间隙锁，因为间隙锁的目的时用来防止插入幻读的。**不分X和S型
- 间隙锁+记录锁Next-key-Lock：**可以防止增、删、改导致的幻读**（记录锁防止删改、间隙锁防止增加），临键锁，锁定一个范围（左开右闭），并锁定记录本身（既保护该记录，又防止其他事务将新记录查到该记录前面），**不能被事务同时持有，其他事务会被阻塞**，分为X型和S型 `select * from result where id>=1 lock in share mode`为S型，select * from result where id>=1 for update为X型
- 插入意向锁：当事务插入一条记录时，**会先判断该记录是否被其他事务加了间隙锁**，如果有则会发生阻塞，就会生成一个插入意向锁并设置成等待状态（并不代表持有了锁），直到上一个事务被提交才被设为正常状态。

##### - 如何加行锁

**加锁的对象是索引（二级索引和聚簇索引），加锁的基本单位是next-key lock临键锁，在某些场景下会退化为记录锁或者间隙锁（在使用记录锁或者间隙锁就可以避免幻读的情况下会退化）。**
==**在读已提交级别下只有记录锁**==

- 通过`select * from performance_schema.data_locks;`能监控加锁的方式，data_locks提供**当前被数据库持有的锁的信息。**data_lock_waits提供锁等待信息，**请求锁的事务和阻塞该请求的事务之间的关系**。
  <img src="C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240425230528830.png" alt="image-20240425230528830" style="zoom:80%;" />
  - lock_type:table为表锁，record为行锁
  - lock_mode:X表示X型临键锁。X，REC_NOT_GAP表示X型记录锁。X，GAP表示间隙锁。IX表示表级X型意向锁
- 主键/唯一索引的等值查询：
  - 存在：如果查的是聚簇索且记录存在的话引退化为记录锁。因为唯一索引的等值查询存在的话使用记录锁就能避免幻读（等值查询本来就只返回一条记录，如果存在就不可能会幻读，因此只要记录锁防止其他线程删除该记录就行）
  - 不存在：若记录不存在，会从索引树找到第一个大于该索引的索引‘5’（非无穷的索引）和该索引‘5’的上一个索引‘1’开始使用一个间隙锁。如有索引1,5，要select id=4的，会将（1,5）进行间隙锁。
- 主键/唯一索引的范围查询
  - 大于、大于等于：对符合条件的每个索引加间隙锁，如有索引1,3,6,8。查id>3和id>4会对（3,6]和(6,8]和(8,supermum]加上临键锁，supermum标志最后一个记录，**supermum可以被多个间隙锁持有，因为supermum并不是个真实的索引**。如果查id>=3，除了以上的间隙锁，还会对3加上记录锁
  - 小于、小于等于：如有索引1,3,6,8。**范围条件不在表中**，查id<=4,会对（-∞，1]加临键锁，（1,3]加临键锁，（3,6）加记录锁。查id<4和id<=4一样。**范围条件在表中**，查id<3,会对（-∞，1]加临键锁，（1,3）加记录锁，查id<=3，会对（-∞，1]加临键锁，（1,3]加间隙锁
- 非唯一索引等值查询
  因为存在两个索引，非唯一索引（二级索引），主键索引，因此加锁时会对这两个索引都加锁，**主键只会对满足条件的记录加记录锁**
  - 存在：因为非唯一索引可能有多个，当ref范围扫描到第一个不符合条件的索引停止，对该不符合条件的索引加间隙锁，对扫描中所有符合条件的加上临键锁。如有非唯一的二级索引1,3,6,8。查id=3，对（1,3]临键锁，（3,6）加间隙锁，因为索引是非唯一的，当有其他线程插入id=6时，可能插入成功也可能插入失败（根据插入的主键和间隙锁中主键的大小）
  - 不存在：对不符合条件的第一个索引加间隙锁。如有非唯一的二级索引1,3,6,8。查id=4，会对（3,6）加间隙锁。
- 非唯一索引范围查询
  - **对符合条件的每个索引加临键锁，不会退化**
- select、update、delete不为索引的字段、
  - **只会对索引加锁，因此不为索引的字段不会走索引加锁，而是全表扫描，会对每个主键索引加间隙锁，相当于锁住了全表**，其他线程的所有操作都会被阻塞。
  - **因此在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了**
  - 如何避免update使用非索引字段造成的全表扫描？：可以将 MySQL 里的 `sql_safe_updates` 参数设置为 1。即当update的where语句中有索引或有limit才能执行成功，delete同时有where和limit才可以不用索引。

- DDL的风险（mdl写表被阻塞的风险）？ 
  如果DDL操作之前存在存在长事务一直不提交，DDL就一直会被阻塞，而**DDL的mdl写锁优先级高于mdl读锁**，因此DDL之后的其他DML操作同时会被阻塞。最后导致服务器挂掉。
  DDL的执行过程：按照表A定义新建一个临时表B、表A加写锁、表B执行DDL操作、将表A数据拷贝到表B、释放表A写锁、删除表A、将表B重命名为表A。
  - 方式一：使用Online DDL允许在DDL时依然能够进行DML操作，避免阻塞，`ALTER TABLE tbl_name ADD PRIMARY KEY (column), ALGORITHM=INPLACE, LOCK=NONE;`拿mdl写锁，降级成mdl读锁，做ddl，升级成mdl写锁，释放mdl锁（拿锁和升级锁会获取MDL写锁）
  - 方式二：使用pt—osc：创建临时表，执行DDL操作，在**原表上创建增删改的触发器**，用于在拷贝时将原表改动更新到新表上，将原标数据更新到新表上，原表删除，新表名字改为原表（但是创建触发器和rename表时都会尝试获取MDL写锁）

##### - 死锁？

- 当事务A使用 `select for update`获取到某个范围的间隙锁，接着事务B也使用 `select for update`获取到相同范围的间隙锁，事务A接下来进行insert插入操作，由于该范围被事务B持有间隙锁，会创建插入意向锁并设置为等待状态等待事务B提交，同样事务B进行insert操作也会创建插入意向锁并设置为等待状态等待事务A提交，**二者相互等待对方提交释放锁陷入等待状态，死锁**。  （**for update阻止幻读，会有间隙锁，唯一索引冲突时insert会加锁，因此当不是唯一索引时insert不会加锁，又有update产生间隙锁，**）
- **间隙锁是可以相互兼容的**，因为间隙锁的设计目的是避免区间被插入，而**间隙锁与插入意向锁是冲突的**
- **使用select for update**是为了防止幻读，普通的select与可重复读
- 但是**next key lock是相互阻塞的**（因为间隙锁兼容，但是X记录锁是阻塞的），但是 (1006, +∞] 的 next-key lock是可以多个事务持有的，因为+∞ 并不是一个真实的记录。

- 发生死锁条件？ 

  - 互斥：该资源是独占的，一次只有一个线程能使用(间隙锁和插入意向锁是互斥的)
  - 占有并等待：对线程来说不会主动释放已占用资源（两个线程都占有了间隙锁，都等待对方释放锁）
  - 不可强占用：不能强制从其他线程中抢占资源（必须等对方释放间隙锁才能加插入意向锁）
  - 循环等待：形成一个循环，都等待对方释放资源（都等对方释放）

- 如何解除死锁？

  1. 设置等待锁超时时间，超过等待时间就回滚该事务

  2. 开启主动死锁检测，发现死锁后主动回滚其中某一个事务，默认为开始

  3. 我优化过一个死锁问题，是临键锁引起的。业务逻辑很简单，（为了保持幂等）先用 SELECT FOR UPDATE 查询数据。如果查询到了数据，那么就执行一段业务逻辑，然后更新结果；如果没有查询到，那么就执行另外一段业务逻辑，然后插入计算结果。

     那么如果 SELECT FOR UPDATE 查找的数据不存在，那么数据库会使用一个临键锁。此时，如果有两个线程加了临键锁，然后又希望插入计算结果，那么就会造成死锁。

     我这个优化也很简单，就是上来先不管三七二十一，直接插入数据。如果插入成功，那么就执行没有数据的逻辑，此时不会再持有临键锁，而是持有了行锁。如果插入不成功，那么就执行有数据的业务逻辑。

- Insert在什么时候加锁？

  - 不冲突时：插入成功则生成**隐式锁**，即如果不发生冲突，就跳过加锁环节，因为版本链存在，因此可以用版本链保护正常插入的数据。

  - 发生冲突时会显示加锁
    - 当遇到间隙锁：生成**插入意向锁并设置为阻塞等待状态**，insert被阻塞
    
    - 当插入记录已存在：
    
      - 当主键已存在（即已经被提交），会先报错并给该主键索引**本来要加的X型临键锁降级为S型记录锁（因为没加成X锁，所以变为S记录锁）**。保证该数据不被其他线程修改，保证一致性
    
      - 当唯一二级索引已存在（即已经被提交），先报错，再加**S型间隙锁**
    
      - 当主键已存在（但还未提交）**（从隐式锁变成显示锁）**：若其他事务B尝试对该记录加锁，则会将隐式锁变为显示**X型记录锁**，且B进入阻塞等待状态，防止事务B读到其他事务未提交的数据导致幻读
    
        

- 乐观锁  回滚重试
  **直到要修改数据才去检查数据是否被持有或修改**，如先select再update，在select与update之间记录可能被别的事务修改导致update失败，

  - 使用CAS来实现（compare and swap）,包含三个操作数，**内存位置V、预期原值A、新值**，如果内存位置的值与预期原值相匹配，就会将该位置的值更细为新值（即我认为位置V的值应该包含值A，如果包含，就把新值B放到这个位置`循环进行 UPDATE xxx SET data = newData WHERE id = 1 AND data = oldData直到成功`id=1为位置A，data = oldData为位置A的值应该为预期原值A，SET data = newData为把新值B放到这个位置，oldData预期原值为上一步用select查到的值，**一般并不用数据库提供的锁机制，而是通过数据版本来实现**，预期原值A可以设置成版本号，即每次更新操作版本号加1，显示的显示版本或使用时间戳这种天然递增的数据（以防止ABA问题即预期原值A可能被修改过又改回来，则会被判断没被经过变化），当并发时会大量出现失败回滚，因此可以减小客观锁的粒度，将预期原值比较从等值比较变成范围比较如`quantity - 1 > 0`
    允许多个线程同时读取（因为根本没有加锁操作），但是只有一个线程可以成功更新数据，并导致其他要更新数据的线程回滚重试
  - 适用于读多写少的场景，乐观锁实现复杂

- 悲观锁 阻塞事务
  事务开启时就加锁保护好资源，**先取锁再访问**，如select for update先加好next key锁，不用担心数据被其他事务更改（即共享资源每次只能有一个线程获得，其他线程阻塞），再进行update等更新操作，**行锁、表锁、synchronized均为悲观锁**

  - 适用于写多读少的场景（因为并发写的概率大，因此要加锁），如金融行业

#### ==日志==

- 慢查询日志
  用来记录在Mysql中**响应时间超过阈值的语句**，用long_query_time来设定阈值，收集完慢sql可以结合explain进行分析优化

  - 慢sql默认不开启，需要手动开启参数，**不是调优需要的话一般不开启慢sql。** `show variable like '%slow_query_log';`查看状态 `set global slow_query_log=on;`

##### - undo log

- undo log  **在事务开启后就开始写入Buffer pool的undo页中**
  记录事务执行过程中回滚需要的操作（即提交前），当崩溃了时可以将还没提交的事务进行回滚
  - 维护ACID的原子性，用于**事务回滚与通过undolog（增删改的回滚）与readview实现MVCC（查）**
  - 为什么需要undo log？：
    1、**提交前崩溃回滚事务**，在事务提交前的执行过程的每一步都记录下回滚所需要的信息，若事务执行途中提交前发生了崩溃或者中止事务，通过undo log可以回滚到事务开启前的数据。
    在插入时记录下记录的主键，回滚时删除主键。在删除时，记下整条记录，回滚时重新插入。在更新时，记下被更新列原来的值，回滚时将该列更新为旧值。
    2、**实现mvcc**，在读提交和读可重复隔离级别下，在普通select快照读通过read view和redo log来实现版本链MCVV。顺着 undo log 的版本链找到满足其可见性的记录。每次产生的undolog都有一个trx_id和roll_pointer指针形成版本链。
  - **undo log如何持久化？：通过redo log来保证持久化**， bufferpool中有undo页，对undo页的修改也会记录到redo log中。                                  

##### - redo log

- redo log    **提交前就写入缓存redo log Buffer中**

  - 在引擎层生成、维护**持久性**，用于**掉电等故障恢复**
  - 为什么需要redo log？：（**崩溃恢复提供持久性，磁盘顺序写提高写性能**）Bufferpool是基于内存的，当事务提交后脏页在还没来得及写入内存的时候断电重启，脏页数据就会丢失。为了防止断电导致数据丢失等问题，当数据更新操作时，（wal预写日志）先在Buffer pool中更新并标记为脏页，再将本次操作记录在redo log中。即**写操作提交并不是立即将脏页写在磁盘上，而是先写redo日志，脏页再在合适时间写到磁盘中**，这样当系统崩溃时，虽然脏数据还没有持久化，但是redo log已经持久化，可以通过redo log将数据恢复到最新状态。**保存当时未被写入磁盘的脏页**
    **可以保证当数据库发送异常重启，已经提交的记录都不会丢失。**
    redo log是顺序写而数据写入磁盘是随机写，**顺序写性能高很多**
  - redo log直接写入磁盘吗？使用缓存redo log buffer（默认16mb），之后再持久化到磁盘中。
    **==redolog刷盘时机==**：（**==未提交也会被持久化==**）
    - 1、mysql正常关闭时
    - 2、当缓存中写入量大于内存空间一半时
    - 3、Innodb后台线程每一秒持久化一次
    - 4、**每次提交持久化一次**（通过**innodb_flush_log_at_trx_commit** 参数控制，默认为1，即每次提交时写入磁盘，0时为提交时不写入磁盘，2时提交时写入操作系统文件缓存）  0时可能会丢1s数据。1时不会丢数据但是性能比0低。2时当操作系统挂了才会丢1s数据，安全性比0强，性能比1强。
  - **redo log是循环写**，磁盘中由两个redo log文件组成，当一个文件被写满时会切换到另一个文件写，因为redo log是为了防止脏页丢失设计的，因此当脏页被写入了磁盘中，那么会将这些旧的记录擦除。使用两个指针write pos和checkpoint分别表示当前写入的位置和当前要擦除的位置，从write pos顺时针到checkpoint的位置为可以继续写的空间，从checkpoint顺时针到write pos的位置表示等待写入磁盘的空间。当write pos追到check point表示当前已经写满，**redo log文件已经被写满，会暂停更新操作，即mysql会被阻塞，先等待脏页被写入磁盘，并标记redo log中哪些可以被擦除，然后擦除后mysql可以恢复运行**
- redo log和undo log的区别？：
  undo记录的是事务开始前的数据状态，即更新前的值
  redo记录的时事务完成后的数据状态，即更新后的值
  事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务（**redolog会恢复已提交的脏页数据和未提交的undo页数据**）。

##### - bin log

- binlog **先写到binlog cache（server层的缓存）中，事务提交再写到binlog文件中（但是binlog文件从系统缓存写到磁盘中时机不同）**

  - 在**server层**生成用于**备份恢复数据与主从复制**（并没有崩溃恢复的能力），记录的是**全量日志**（而不是循环写）
  - 服务端**收到提交事务请求先写入binlog再提交**，会把执行过程中所有操作写入binlog文件，
  - binlog和redolog的区别有4个
    1.  适用对象：binog是server层实现的日志，所有存储引擎都可以用，redolog是InnoDB实现的
    2.  文件格式不一样：binlog有statement（记录下每个sql语句）、row（记录被修改的每行数据）、mixed（结合以上两中）三种格式。而redolog记录的是某表的某页的某偏移量做了某种更新
    3.  写入方式不一样：binlog是顺序写，**保存全量日志**。redolog是循环写，写满就从头写，**保存的是未被写入磁盘的脏页**
    4.  用途不一样：binlog用于恢复备份数据、主从复制。redolog用于掉电故障恢复等。
  - 为什么binlog需要对每个线程分配一片内存缓存binlig cache？而redolog不需要
    因为binlog的事务是不能拆开的，主库中是以事务为单位进行执行，**所以在从库的时候也需要以事务为单位，而不是每个操作执行都交错传给从库，会导致事务的binlog被拆开**，破坏了原子性，因此给每个线程都分配了binlog cache缓存，再以binlog cache为单位写到磁盘中。
  - **binlog什么时候刷盘？**
    **因为一个事务的binlog是不可以分开的，一个线程只能同时进行一个事务，所以每个线程分配一片内存binlog cache，提交的时候以每个线程的binlog cache为单位，若binglog cache是被拆开来提交的在从库中会被当做多个事务来执行，破坏了原子性和执行顺序**，
    - 1、每次事务提交时先调用write（）将binlog cache写入先binlog文件中（**binlog文件在系统缓存page cache中**，所以速度快）。
      2、再使用参数synch_binlog控制调用fsync（）使得binlog文件刷新到磁盘的频率。
      - 0时只write（）写在系统缓存中，由系统决定何时fsync（）写到磁盘上（**可能会丢失多个事务**）。
      - 1时**每次提交都会write（）并立即fsync（）写到磁盘中**（**最多丢失一个事务**）。
      - 大于等于2时表示积累N个事务后再fsync（）刷到磁盘上（**可能丢掉N个事务**））
        <img src="C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240427152058039.png" alt="image-20240427152058039" style="zoom:67%;" />
  - 执行器与Innodb执行update的过程![image-20240205224027832](C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240205224027832.png)
- 为什么要buffer pool？
  因为Mysql中数据都是存放在磁盘中的，当从磁盘中读取该记录时，在内存中修改后可以缓存在buffer pool中，不用每执行一次更新就进行一次磁盘IO，占用性能，且当下次sql语句命中缓存中数据时，不用再去磁盘中找，提升读写性能。

  - buffer pool中除了缓存数据页、索引页、锁信息、插入缓存、还有undo页。**undo页用于缓存undo log**，undo log 会写入 Buffer Pool 中的 Undo 页面而不用访问undo log时每次都去磁盘中找undo log，如果对应的undo页已经在缓存中，那么可以直接从缓存中获取，更有效的执行回滚操作

##### - 两阶段提交

- Commit两阶段提交： **保证redolog和binlog写入的一致性**
  事务提交后，redo log和binlog都要刷写到磁盘。但有可能导致由于**mysql宕机造成半成功状态**，如果redo写了，binlog没写，从库的数据会出错，主库bufferpool的数据可以通过redo恢复。如果binlog写了，redo没写，那么主库的数据会出错，从库的数据通过binlog更新到新值了。**无论哪个没成功都会导致主从数据不一致**。
  - 因此使用**两阶段提交保证二者要么全成功要么全失败，保证==分布式事务一致性==**
  - **redo log时机：先写到redo log buffer中，mysql关闭、当内存写了超过一半、每一秒、事务提交**。
    **binlog 刷写时机：先写到binlog cache中，提交时写到binlog文件中（在系统缓存中），然后由synch_binlog为0时系统决定刷写时机，1时每次提交刷写，大于等于2时没提交N个事务刷写一次**
  - 即将redo log的写入拆为两个步骤，prepare和commit阶段，中间插入binlog的写入。将XA事务ID写入到redo log，redolog对应的XA事务状态设置为prepare，将redolog持久化。将XA事务ID写入到binlog，binlog持久化并将redolog状态改为commit（状态改变不用写到磁盘中，可以写到内存中，因为只要binlog写成功，binlog中有XA事务ID即可，就算redolog磁盘中事务状态为prepare也没关系，一样会被认定为事务已经执行成功，prepare只是用来扫描磁盘时检查可能需要回滚的事务），**binlog作为协调者**（binlog中是否有XA事务ID决定了是否回滚，相当于协调者决定是否回滚）
  - 异常重启后如何处理？重启后会扫描redolog文件，查看prepare状态的redolog（此时redolog已经持久化了），分为两种情况，当binlog中没有XA事务ID，说明binlog还没刷盘，回滚事务。当binlog中有XA事务ID，说明binlog已经刷盘，则将prepare状态改为commit提交。**对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID**，**即保证了redolog和binlog中数据的一致性**
  - ==因此**redolog可以在事务提交前就写入磁盘，如果没有提交就崩溃了，因为事务两阶段提交存在，由于binlog要在事务提交后才能写磁盘，此时还没写磁盘，binlog文件中没有XA事务的ID，所以redolog会被回滚**。但是binlog必须提交后才能持久化，否则还没提交的事务可能由于binlog文件中已经提前有XA事务ID不会被回滚了，造成事务没提交就被持久化且无法回滚了==
  - 两阶段提交的问题？：**磁盘IO很高**（如果双1的配置每次提交进行两次刷盘），**锁竞争激烈**（两阶段提交保证单个事务两个日志的一致性，多个事务时要加mutex锁保证两个日志提交顺序一致，每次提交事务需要先获得锁才能进行prepare阶段（redolog写入XA事务ID并设为prepare状态然后刷盘），commit完成才释放锁，下一个事务才可以进行prepare操作）
- 组提交
  - 解决锁竞争问题：**多个事务提交时，将多个binlog刷盘操作合并成一个，减少磁盘IO次数。**
    组提交prepare阶段不变（redo中写入XA事务ID，设为prepare状态并刷盘），**将commit阶段分为三个过程flush、sync、commit每个过程都有一个队列，每个阶段有单独的锁保护**，第一个进入的事务为leader领导坐在队列的所有事务。
  - flush阶段先把redolog进行write + fsync磁盘（即prepare），并且将binlog写到binlog文件中（write）如果在flush阶段完成后崩溃由于binlog磁盘中没有该XA事务ID，所以会回滚事务。
  - sync阶段，这个阶段**会等待不止一组队列的binlog一起进行fsync刷盘操作**，目的是为了组合更多事务的binlog一起刷盘。在这一步完成后崩溃由于binlog中已经有了XA事务ID。重启后会进行事务的提交
  - commit阶段，将redo log状态设置为commit。

8. Mysql磁盘IO很高怎么优化？
   
   在将redolog和binlog刷写到磁盘会有磁盘IO。
   
   - 可以通过**控制组提交sync的等待时长**或者**控制sync等待的事务数**（尽可能的将更多的事务binlog一起刷盘），即使Mysql崩溃了也没问题（因为在commit的flush阶段就已经写到系统缓存page cache中了），将尽可能多的binlog一起刷写。
   - 将binlog的刷盘参数调大（每次提交都write到系统缓存，但是N个事务才一起刷盘）
   - redolog的参数设置为2，即每次提交不刷盘，而是写到系统缓存，系统判断什么时候刷盘。
   

#### ==高可用==

##### - 主从复制

即如何保持主从数据一致性？  

**AsyncJob不用主从复制，因为读数据并不会比写多**
*Redis作为Mysql的缓存？**  当用户查看订单时，通过查询订单缓存，帮助Mysql抵挡住大部分查询请求。不行，因为缓存的原则之一时缓存的命中率足够高，否则很多的请求会穿透缓存，最终打在数据库上，订单对于每个用户来说都不同，除非全量缓存，否则命中率很低，还是会打到数据库上

大部分场景是读多写少，读写的请求量可以达到几个数量级（如购物平台的商品浏览量肯定远大于下单量），**因此当单台MySQL无法满足要求时要有多个相同数据的MySQL实例组成的集群来承担读写请求**，首先读写分离（方便对读做扩展），
<img src="C:\Users\10122\AppData\Roaming\Typora\typora-user-images\image-20240318190536104.png" alt="image-20240318190536104" style="zoom:50%;" />

- 步骤：

  1. 主库先写入binlog日志，再提交事务并更新本地存储，返回给客户端成功的响应

  2. 单独一个log dump线程将binlog日志从主库写到从库的relay中继日志中，返回给主库复制成功的响应
  3. 从库创建一个回放binlog的线程，执行relay log中的操作，实现主从一致性

- 复制方式有：同步复制、异步复制、半同步复制 （**不同的数据一致性要求**）
  - 同步复制事务线程等待所有从库复制成功的响应，才给客户端返回结果。（性能很差，因为需要所有从节点返回响应，其次如果有一个从节点挂了就会影响业务。）
  - 异步复制事务线程不用等待从库复制成功响应就给客户端返回结果（单独开启一个log dump线程复制，一旦主库发生宕机，数据就会丢失）
  - 半同步复制事务线程只要一部分从库复制成功就给客户端响应（主库宕机数据不会丢失）
- 从库是不是越多越好？不是，因为主库给从库发送日志需要创建线程，当从库多了主库中的IO线程也会变多，对主库的资源消耗较高。所以一般1主2从1备主
- 主从延迟怎么解决？（即主库写到从库前，有请求来访问数据，可能从库读取不到信息）
  **如将数据写入主库的同时写入redis缓存，查询的时候先查询缓存就能获取到**





### 其他方面  (mysql语句)

1. 登录 `musql -uroot -p`
2. 查询多少客户端连接`show processlist`
3. 设置最大空闲时长（空闲超过时间连接会断开）默认8h`show variables like 'wait_timeout'` `set wait_timeout=`
4. 手动关闭连接 `kill connection+6` 6为ID号
5. 设置服务器最大客户端连接数量 `show variables like 'max_connections'` 
6. 





